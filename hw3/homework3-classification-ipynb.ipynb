{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pandas\n!pip install torch\n!pip install nltk\n!pip install tqdm\n!pip install seaborn\n!pip install numpy\n!pip install sklearn","metadata":{"id":"Y0fOWhqwW-AT","outputId":"29c46c8c-d277-44db-c6a8-0adc2ca5fa26","execution":{"iopub.status.busy":"2021-12-18T10:12:17.486035Z","iopub.execute_input":"2021-12-18T10:12:17.486729Z","iopub.status.idle":"2021-12-18T10:15:41.871555Z","shell.execute_reply.started":"2021-12-18T10:12:17.486620Z","shell.execute_reply":"2021-12-18T10:15:41.870388Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import nltk\nnltk.download('punkt')","metadata":{"id":"u3wugeOHW-AV","outputId":"654b9045-4cfa-4e21-fcd5-8d467e743e37","execution":{"iopub.status.busy":"2021-12-18T10:17:31.178424Z","iopub.execute_input":"2021-12-18T10:17:31.179296Z","iopub.status.idle":"2021-12-18T10:17:31.352497Z","shell.execute_reply.started":"2021-12-18T10:17:31.179251Z","shell.execute_reply":"2021-12-18T10:17:31.351667Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Скачиваем данные","metadata":{"id":"m9XIrxSmW-AX"}},{"cell_type":"code","source":"!wget https://raw.githubusercontent.com/semensorokin/DLforNLP_course_material/master/Homework2/answers_subsample.csv","metadata":{"id":"ep1FB3IBW-AY","outputId":"2d9adcdc-aef8-438b-f27f-022ab0674eb9","execution":{"iopub.status.busy":"2021-12-18T10:17:35.080155Z","iopub.execute_input":"2021-12-18T10:17:35.080789Z","iopub.status.idle":"2021-12-18T10:17:36.222431Z","shell.execute_reply.started":"2021-12-18T10:17:35.080747Z","shell.execute_reply":"2021-12-18T10:17:36.221335Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# если ругается на то, что нет wget\n# !apt-get install wget","metadata":{"id":"BWA7IClKW-Aa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls -l","metadata":{"id":"qJpFTPpsW-Ac","outputId":"b66ad212-5181-4f41-d08d-c779bdb2f954","execution":{"iopub.status.busy":"2021-12-18T10:17:48.129176Z","iopub.execute_input":"2021-12-18T10:17:48.129503Z","iopub.status.idle":"2021-12-18T10:17:48.927068Z","shell.execute_reply.started":"2021-12-18T10:17:48.129467Z","shell.execute_reply":"2021-12-18T10:17:48.926091Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import pandas as pd","metadata":{"id":"qmzaEwy9W-Ae","execution":{"iopub.status.busy":"2021-12-18T10:17:48.929689Z","iopub.execute_input":"2021-12-18T10:17:48.930231Z","iopub.status.idle":"2021-12-18T10:17:48.936905Z","shell.execute_reply.started":"2021-12-18T10:17:48.930173Z","shell.execute_reply":"2021-12-18T10:17:48.935736Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('answers_subsample.csv')","metadata":{"id":"BbDKxq4EW-Ag","execution":{"iopub.status.busy":"2021-12-18T10:17:49.873309Z","iopub.execute_input":"2021-12-18T10:17:49.874228Z","iopub.status.idle":"2021-12-18T10:17:51.209131Z","shell.execute_reply.started":"2021-12-18T10:17:49.874183Z","shell.execute_reply":"2021-12-18T10:17:51.208200Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"id":"hcAdsbS7W-Ai","outputId":"3694b3c0-566d-4185-e875-efbc33e6d13c","execution":{"iopub.status.busy":"2021-12-18T10:17:51.214920Z","iopub.execute_input":"2021-12-18T10:17:51.217574Z","iopub.status.idle":"2021-12-18T10:17:51.270867Z","shell.execute_reply.started":"2021-12-18T10:17:51.217513Z","shell.execute_reply":"2021-12-18T10:17:51.270014Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"data.category.value_counts() * 100 / data.shape[0]","metadata":{"id":"90tXLjfsW-Aj","outputId":"7d536f85-af09-4790-9f21-feff820e5a88","execution":{"iopub.status.busy":"2021-12-18T10:17:51.292323Z","iopub.execute_input":"2021-12-18T10:17:51.292688Z","iopub.status.idle":"2021-12-18T10:17:51.399606Z","shell.execute_reply.started":"2021-12-18T10:17:51.292650Z","shell.execute_reply":"2021-12-18T10:17:51.398605Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# Предобученные эмбеддинги\n[Источник](https://fasttext.cc/docs/en/crawl-vectors.html)  \nВы можете взять любые word2vec подобные эмббединги. Если вы хотите использовать elmo, bert, etc сначала попробуйте с word2vec подобными эмббедингами, а потом можете перейти к более сложным моделям.  \nНиже мы сначала скачиваем, а потом распоковываем эмбеддинги.","metadata":{"id":"gfHbifWIW-Al"}},{"cell_type":"code","source":"!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ru.300.vec.gz\n!gzip -d cc.ru.300.vec.gz","metadata":{"id":"PVhCzM3LW-Al","outputId":"d7be80de-38df-4fec-9769-c126ded07dc7","execution":{"iopub.status.busy":"2021-12-18T10:17:52.463730Z","iopub.execute_input":"2021-12-18T10:17:52.464069Z","iopub.status.idle":"2021-12-18T10:19:17.092644Z","shell.execute_reply.started":"2021-12-18T10:17:52.463998Z","shell.execute_reply":"2021-12-18T10:19:17.091505Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"!ls -l","metadata":{"id":"eJcT1qPZW-An","outputId":"775a556a-2f8b-41ee-f1eb-24b6f17830a4","execution":{"iopub.status.busy":"2021-12-18T10:19:17.095056Z","iopub.execute_input":"2021-12-18T10:19:17.095358Z","iopub.status.idle":"2021-12-18T10:19:17.874797Z","shell.execute_reply.started":"2021-12-18T10:19:17.095322Z","shell.execute_reply":"2021-12-18T10:19:17.873705Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"from nltk.tokenize import word_tokenize, wordpunct_tokenize\nfrom tqdm import tqdm","metadata":{"id":"M0lwyZUFW-Ap","execution":{"iopub.status.busy":"2021-12-18T10:19:17.876841Z","iopub.execute_input":"2021-12-18T10:19:17.877306Z","iopub.status.idle":"2021-12-18T10:19:25.244886Z","shell.execute_reply.started":"2021-12-18T10:19:17.877241Z","shell.execute_reply":"2021-12-18T10:19:25.243751Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# потом можете добавить свою предобработку\n\ndef process_text(text):\n    \n    words = wordpunct_tokenize(text.lower())\n    \n    return words","metadata":{"id":"QQpX51Y4W-Aq","execution":{"iopub.status.busy":"2021-12-18T10:19:25.248179Z","iopub.execute_input":"2021-12-18T10:19:25.248526Z","iopub.status.idle":"2021-12-18T10:19:30.538846Z","shell.execute_reply.started":"2021-12-18T10:19:25.248485Z","shell.execute_reply":"2021-12-18T10:19:30.537323Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"word2freq = {}\nlengths = []\n\nfor text in tqdm(data.text):\n    \n    words = process_text(text)\n    \n    lengths.append(len(words))\n    \n    for word in words:\n        \n        if word in word2freq:\n            word2freq[word] += 1\n        else:\n            word2freq[word] = 1","metadata":{"id":"HyI2erCDW-Ar","outputId":"01f4b1a1-44ee-4f98-a70e-8533039a5119","execution":{"iopub.status.busy":"2021-12-18T10:19:30.546848Z","iopub.execute_input":"2021-12-18T10:19:30.550240Z","iopub.status.idle":"2021-12-18T10:19:34.343892Z","shell.execute_reply.started":"2021-12-18T10:19:30.550166Z","shell.execute_reply":"2021-12-18T10:19:34.343057Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nfrom matplotlib import pyplot as plt","metadata":{"id":"FGzDm0ptW-At","execution":{"iopub.status.busy":"2021-12-18T10:19:34.345686Z","iopub.execute_input":"2021-12-18T10:19:34.346041Z","iopub.status.idle":"2021-12-18T10:19:34.503960Z","shell.execute_reply.started":"2021-12-18T10:19:34.345982Z","shell.execute_reply":"2021-12-18T10:19:34.503068Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nplt.title('Распределение длин слов в текстах')\nplt.xlabel('Длина предложения')\nplt.ylabel('Доля')\nsns.distplot(lengths)","metadata":{"id":"iZBR-aYDW-Av","outputId":"cdfad804-25be-4bf0-dd81-c72a07970138","execution":{"iopub.status.busy":"2021-12-18T10:19:34.505454Z","iopub.execute_input":"2021-12-18T10:19:34.505755Z","iopub.status.idle":"2021-12-18T10:19:35.943877Z","shell.execute_reply.started":"2021-12-18T10:19:34.505717Z","shell.execute_reply":"2021-12-18T10:19:35.943062Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"upper_threshold = 32\nlower_threshold = 3\n\ncorrect_percent = len([sent_len for sent_len in lengths \n                       if sent_len <= upper_threshold and sent_len >= lower_threshold]) * 100 / len(lengths)\n\n'{:.2f} % наших текстов входят в промежуток от {} до {} слов'.format(correct_percent, lower_threshold, upper_threshold)","metadata":{"id":"OBzmPqXIW-Aw","outputId":"9eec7d78-3c04-42fa-9953-119aa42242be","execution":{"iopub.status.busy":"2021-12-18T10:19:35.945475Z","iopub.execute_input":"2021-12-18T10:19:35.945963Z","iopub.status.idle":"2021-12-18T10:19:35.983585Z","shell.execute_reply.started":"2021-12-18T10:19:35.945919Z","shell.execute_reply":"2021-12-18T10:19:35.982659Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"len(word2freq)","metadata":{"id":"GbSer_0bW-Ay","outputId":"7bfa3a41-a9cb-416f-f2b2-d6880efd55c9","execution":{"iopub.status.busy":"2021-12-18T10:19:35.985547Z","iopub.execute_input":"2021-12-18T10:19:35.986247Z","iopub.status.idle":"2021-12-18T10:19:35.993580Z","shell.execute_reply.started":"2021-12-18T10:19:35.986191Z","shell.execute_reply":"2021-12-18T10:19:35.992683Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"'{} слов, которые встречались 3 и менее раз'.format(len([word for word in word2freq if word2freq[word] <= 3]))","metadata":{"id":"szg6XD3EW-Az","outputId":"43f425f9-5b48-4708-f07d-36b12ea93501","execution":{"iopub.status.busy":"2021-12-18T10:19:35.997998Z","iopub.execute_input":"2021-12-18T10:19:35.998355Z","iopub.status.idle":"2021-12-18T10:19:36.060792Z","shell.execute_reply.started":"2021-12-18T10:19:35.998309Z","shell.execute_reply":"2021-12-18T10:19:36.059987Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"# Читаем файл с эмбеддингами\n### Этот файл с 300 числами для 2 000 000 слов и он может не влезть в память\nПоэтому прочитаем только те слова, которые мы знаем","metadata":{"id":"bZbOg0FqW-A1"}},{"cell_type":"code","source":"import numpy as np","metadata":{"id":"T1Yx_qr-W-A2","execution":{"iopub.status.busy":"2021-12-18T10:19:36.062378Z","iopub.execute_input":"2021-12-18T10:19:36.062708Z","iopub.status.idle":"2021-12-18T10:19:36.069737Z","shell.execute_reply.started":"2021-12-18T10:19:36.062665Z","shell.execute_reply":"2021-12-18T10:19:36.068734Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"word2index = {'PAD': 0}\nvectors = []\n    \nword2vec_file = open('cc.ru.300.vec')\n    \nn_words, embedding_dim = word2vec_file.readline().split()\nn_words, embedding_dim = int(n_words), int(embedding_dim)\n\n# Zero vector for PAD\nvectors.append(np.zeros((1, embedding_dim)))\n\nprogress_bar = tqdm(desc='Read word2vec', total=n_words)\n\nwhile True:\n\n    line = word2vec_file.readline().strip()\n\n    if not line:\n        break\n        \n    current_parts = line.split()\n\n    current_word = ' '.join(current_parts[:-embedding_dim])\n\n    if current_word in word2freq:\n\n        word2index[current_word] = len(word2index)\n\n        current_vectors = current_parts[-embedding_dim:]\n        current_vectors = np.array(list(map(float, current_vectors)))\n        current_vectors = np.expand_dims(current_vectors, 0)\n\n        vectors.append(current_vectors)\n\n    progress_bar.update(1)\n\nprogress_bar.close()\n\nword2vec_file.close()\n\nvectors = np.concatenate(vectors)","metadata":{"id":"BLEgfnaWW-A4","outputId":"279a0959-ac48-4999-8cf7-26274fe2f874","execution":{"iopub.status.busy":"2021-12-18T10:19:36.072201Z","iopub.execute_input":"2021-12-18T10:19:36.073175Z","iopub.status.idle":"2021-12-18T10:21:04.452371Z","shell.execute_reply.started":"2021-12-18T10:19:36.073121Z","shell.execute_reply":"2021-12-18T10:21:04.451307Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"len(word2index)","metadata":{"id":"AYJMzgpnW-A7","outputId":"1dbf297e-3a44-4fcd-8c9c-149015cf4cfd","execution":{"iopub.status.busy":"2021-12-18T10:21:04.454596Z","iopub.execute_input":"2021-12-18T10:21:04.455277Z","iopub.status.idle":"2021-12-18T10:21:04.462991Z","shell.execute_reply.started":"2021-12-18T10:21:04.455225Z","shell.execute_reply":"2021-12-18T10:21:04.461939Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"unk_words = [word for word in word2freq if word not in word2index]\nunk_counts = [word2freq[word] for word in unk_words]\nn_unk = sum(unk_counts) * 100 / sum(list(word2freq.values()))\n\nsub_sample_unk_words = {word: word2freq[word] for word in unk_words}\nsorted_unk_words = list(sorted(sub_sample_unk_words, key=lambda x: sub_sample_unk_words[x], reverse=True))\n\nprint('Мы не знаем {:.2f} % слов в датасете'.format(n_unk))\nprint('Количество неизвестных слов {} из {}, то есть {:.2f} % уникальных слов в словаре'.format(\n    len(unk_words), len(word2freq), len(unk_words) * 100 / len(word2freq)))\nprint('В среднем каждое встречается {:.2f} раз'.format(np.mean(unk_counts)))\nprint()\nprint('Топ 5 невошедших слов:')\n\nfor i in range(5):\n    print(sorted_unk_words[i], 'с количеством вхождениий -', word2freq[sorted_unk_words[i]])","metadata":{"id":"KE06fafiW-A8","outputId":"18c80479-7923-4163-afa9-27a87fd7a29c","execution":{"iopub.status.busy":"2021-12-18T10:21:04.465045Z","iopub.execute_input":"2021-12-18T10:21:04.465631Z","iopub.status.idle":"2021-12-18T10:21:04.623613Z","shell.execute_reply.started":"2021-12-18T10:21:04.465579Z","shell.execute_reply":"2021-12-18T10:21:04.622520Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"# Потеря 2.5 % слов в датасете\nЭта ситуация не то, чтобы сильно плохая, в учебных целях нормально, к тому же в среднем они редко встречаются. Вы можете поиграть с предобработкой.","metadata":{"id":"GFPNApUjW-A9"}},{"cell_type":"code","source":"import torch","metadata":{"id":"_fo1fB6JW-A-","execution":{"iopub.status.busy":"2021-12-18T10:21:04.625432Z","iopub.execute_input":"2021-12-18T10:21:04.626970Z","iopub.status.idle":"2021-12-18T10:21:06.323319Z","shell.execute_reply.started":"2021-12-18T10:21:04.626913Z","shell.execute_reply":"2021-12-18T10:21:06.322434Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"- 128 - размер батча\n- 64 - количество слов\n- 1024 - эмбеддинг слова","metadata":{"id":"pEKAjCg3W-BA"}},{"cell_type":"code","source":"x = torch.rand(128, 64, 1024)","metadata":{"id":"D19pDyQBW-BA","execution":{"iopub.status.busy":"2021-12-18T10:21:06.324971Z","iopub.execute_input":"2021-12-18T10:21:06.325313Z","iopub.status.idle":"2021-12-18T10:21:06.408726Z","shell.execute_reply.started":"2021-12-18T10:21:06.325268Z","shell.execute_reply":"2021-12-18T10:21:06.407860Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"lstm = torch.nn.LSTM(1024, 512, batch_first=True)","metadata":{"id":"Yxsxr7edW-BB","execution":{"iopub.status.busy":"2021-12-18T10:21:06.410216Z","iopub.execute_input":"2021-12-18T10:21:06.410520Z","iopub.status.idle":"2021-12-18T10:21:06.450203Z","shell.execute_reply.started":"2021-12-18T10:21:06.410481Z","shell.execute_reply":"2021-12-18T10:21:06.449274Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"%%timeit\n\npred = lstm(x)","metadata":{"id":"TZy0lKr2W-BC","outputId":"6df9d230-f551-4f43-f558-53bf9ccaea47","execution":{"iopub.status.busy":"2021-12-18T10:21:06.451972Z","iopub.execute_input":"2021-12-18T10:21:06.452347Z","iopub.status.idle":"2021-12-18T10:21:11.695864Z","shell.execute_reply.started":"2021-12-18T10:21:06.452296Z","shell.execute_reply":"2021-12-18T10:21:11.694903Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"# А что GPU?","metadata":{"id":"s611e34SW-BE"}},{"cell_type":"code","source":"print('Доступна ли видеокарта:', torch.cuda.is_available())\nprint('Если недоступна, поменяйте runtime, если в колабе')","metadata":{"id":"xjFlWdgtW-BE","outputId":"333ef0d4-e477-41f9-8277-ae559f9b2a97","execution":{"iopub.status.busy":"2021-12-18T10:21:11.697337Z","iopub.execute_input":"2021-12-18T10:21:11.699206Z","iopub.status.idle":"2021-12-18T10:21:11.751426Z","shell.execute_reply.started":"2021-12-18T10:21:11.699155Z","shell.execute_reply":"2021-12-18T10:21:11.750206Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# универсальных способ задать device\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n# если доступна gpu, то давайте ее использовать, но в этом задании должны использовать","metadata":{"id":"jaMMD5CDW-BG","execution":{"iopub.status.busy":"2021-12-18T10:21:11.753529Z","iopub.execute_input":"2021-12-18T10:21:11.754284Z","iopub.status.idle":"2021-12-18T10:21:11.761939Z","shell.execute_reply.started":"2021-12-18T10:21:11.754231Z","shell.execute_reply":"2021-12-18T10:21:11.760965Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# перенесли x на gpu\nx_gpu = x.to(device)","metadata":{"id":"GeQCiSYdW-BH","execution":{"iopub.status.busy":"2021-12-18T10:21:11.763751Z","iopub.execute_input":"2021-12-18T10:21:11.764490Z","iopub.status.idle":"2021-12-18T10:21:14.376331Z","shell.execute_reply.started":"2021-12-18T10:21:11.764431Z","shell.execute_reply":"2021-12-18T10:21:14.375456Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# зададим lstm на gpu\nlstm_gpu = torch.nn.LSTM(1024, 512, batch_first=True)\nlstm_gpu = lstm_gpu.to(device)","metadata":{"id":"S_qUdMcbW-BJ","execution":{"iopub.status.busy":"2021-12-18T10:21:14.378117Z","iopub.execute_input":"2021-12-18T10:21:14.378425Z","iopub.status.idle":"2021-12-18T10:21:15.131609Z","shell.execute_reply.started":"2021-12-18T10:21:14.378384Z","shell.execute_reply":"2021-12-18T10:21:15.130677Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"%%timeit\n\npred = lstm_gpu(x_gpu)","metadata":{"id":"hSUQmRgtW-BK","outputId":"ba489497-1c30-4416-cbd4-601d614fba63","execution":{"iopub.status.busy":"2021-12-18T10:21:15.136168Z","iopub.execute_input":"2021-12-18T10:21:15.136481Z","iopub.status.idle":"2021-12-18T10:21:23.151181Z","shell.execute_reply.started":"2021-12-18T10:21:15.136440Z","shell.execute_reply":"2021-12-18T10:21:23.150276Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"# У меня на 1070 TI скорость уменьшилась с 381мс до 41мс, то есть в 9.29 раз","metadata":{"id":"gPvqNWkQW-BM"}},{"cell_type":"code","source":"# если у нас модель на гпу, а то, что мы туда подаем нет, то работать не будет\n# справедлива и обратная ситуация\n\n# выскочит ошибка\n# посмотрите на нее, возможно, вы еще встретитесь\n# pred = lstm_gpu(x)","metadata":{"id":"FaPKGO5aW-BN","execution":{"iopub.status.busy":"2021-12-18T10:21:23.152658Z","iopub.execute_input":"2021-12-18T10:21:23.153536Z","iopub.status.idle":"2021-12-18T10:21:23.157837Z","shell.execute_reply.started":"2021-12-18T10:21:23.153487Z","shell.execute_reply":"2021-12-18T10:21:23.157017Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"# Важные и не очень интуитивные моменты про LSTM и CNN в торче","metadata":{"id":"9NX5HHDOW-BO"}},{"cell_type":"markdown","source":"По умолчанию LSTM принимает данные с такой размерностью:\n```python\n(seq_len, batch, input_size)\n```\nСделано это с целью оптимизации на более низком уровне.  \nМы оперируем такими объектами:\n```python\n(batch, seq_len, input_size)\n```\nЧтобы LSTM у нас заработала правильно, мы можем либо передать параметр ```batch_first=True``` во время инициализации слоя,\nлибо транспонировать (поменять) первую и вторую размерность у нашего x перед подачей в слой.  \n[Подробнее про LSTM](https://pytorch.org/docs/stable/nn.html#lstm)","metadata":{"id":"zKr22rklW-BP"}},{"cell_type":"markdown","source":"- 128 - размер батча\n- 64 - количество слов\n- 1024 - эмбеддинг слова","metadata":{"id":"Bny8SvCgW-BQ"}},{"cell_type":"code","source":"# первый способ\nlstm = torch.nn.LSTM(1024, 512, batch_first=True)\n\npred, mem = lstm(x)","metadata":{"id":"vc-bLok2W-BQ","execution":{"iopub.status.busy":"2021-12-18T10:21:23.159716Z","iopub.execute_input":"2021-12-18T10:21:23.160070Z","iopub.status.idle":"2021-12-18T10:21:23.879161Z","shell.execute_reply.started":"2021-12-18T10:21:23.160026Z","shell.execute_reply":"2021-12-18T10:21:23.878250Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"pred.shape","metadata":{"id":"OHpit-1tW-BR","outputId":"de714617-37d4-486f-fc6a-a4535b1bc561","execution":{"iopub.status.busy":"2021-12-18T10:21:23.880577Z","iopub.execute_input":"2021-12-18T10:21:23.880901Z","iopub.status.idle":"2021-12-18T10:21:23.891025Z","shell.execute_reply.started":"2021-12-18T10:21:23.880859Z","shell.execute_reply":"2021-12-18T10:21:23.889991Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"lstm = torch.nn.LSTM(1024, 512)\n\n# меняем размерность batch и seq_len местами\nx_transposed = x.transpose(0, 1)\npred_transposed, mem = lstm(x_transposed)","metadata":{"id":"ru_WzGSJW-BS","execution":{"iopub.status.busy":"2021-12-18T10:21:23.893194Z","iopub.execute_input":"2021-12-18T10:21:23.893708Z","iopub.status.idle":"2021-12-18T10:21:24.674546Z","shell.execute_reply.started":"2021-12-18T10:21:23.893660Z","shell.execute_reply":"2021-12-18T10:21:24.673642Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"# у нас все еще осталась размерность (seq_len, batch, input_size)\npred_transposed.shape","metadata":{"id":"NHdBavTWW-BT","outputId":"99d68d81-f4e2-4e1b-886b-2ebb041e1b71","execution":{"iopub.status.busy":"2021-12-18T10:21:24.680265Z","iopub.execute_input":"2021-12-18T10:21:24.681055Z","iopub.status.idle":"2021-12-18T10:21:24.688085Z","shell.execute_reply.started":"2021-12-18T10:21:24.680990Z","shell.execute_reply":"2021-12-18T10:21:24.687248Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# просто транспонируем еще раз\npred = pred_transposed.transpose(0, 1)\npred.shape","metadata":{"id":"Rcxv55j7W-BV","outputId":"741b1c7e-adf2-4d63-859c-c281fc3c6bd3","execution":{"iopub.status.busy":"2021-12-18T10:21:24.689944Z","iopub.execute_input":"2021-12-18T10:21:24.690503Z","iopub.status.idle":"2021-12-18T10:21:24.702176Z","shell.execute_reply.started":"2021-12-18T10:21:24.690450Z","shell.execute_reply":"2021-12-18T10:21:24.701314Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"## Conv1d & MaxPool1d\nПримерно такая же ситуация происходит со сверточными слоями и пулингами.  \n1d реализация как раз для текстов, в ней матрица-фильтр ходит только по одной размерности.  \n[Подробнее про CNN](https://pytorch.org/docs/stable/nn.html#conv1d)  \n[Подробнее про пулинг](https://pytorch.org/docs/stable/nn.html#maxpool1d)  \nОжидается такая размерность:\n```python\n(batch, input_size, seq_len)\n```\nМы все еще хоти подавать такую размерность:\n```python\n(batch, seq_len, input_size)\n```\nВ случае со свертками и пулингами у нас есть вариант только транспонировать x перед подачей и транспонировать полученный результат. Обратите внимание, что транспонируем мы первую и вторую размерность (индексация с нуля).","metadata":{"id":"PmJt6cqkW-BW"}},{"cell_type":"code","source":"x.shape","metadata":{"id":"TyM8Xl24W-BX","outputId":"df136e61-ae27-4c78-e4fb-7ccaf727f160","execution":{"iopub.status.busy":"2021-12-18T10:21:24.703914Z","iopub.execute_input":"2021-12-18T10:21:24.704585Z","iopub.status.idle":"2021-12-18T10:21:24.710800Z","shell.execute_reply.started":"2021-12-18T10:21:24.704537Z","shell.execute_reply":"2021-12-18T10:21:24.709899Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"- 128 - размер батча\n- 64 - количество слов\n- 1024 - эмбеддинг слова","metadata":{"id":"grPNMjEZW-BY"}},{"cell_type":"code","source":"# in_channels - размер входных эмбеддингов\n# out_channels - количество/какой размер эмбеддингов мы хотим получить\n# kernel_size - размер окна/н-граммы\ncnn = torch.nn.Conv1d(in_channels=1024, out_channels=512, kernel_size=3)","metadata":{"id":"btJ-ApiOW-BY","execution":{"iopub.status.busy":"2021-12-18T10:21:24.712518Z","iopub.execute_input":"2021-12-18T10:21:24.713026Z","iopub.status.idle":"2021-12-18T10:21:24.737771Z","shell.execute_reply.started":"2021-12-18T10:21:24.712954Z","shell.execute_reply":"2021-12-18T10:21:24.736898Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"# выпадет ошибка, посмотрите какая\n# pred = cnn(x)","metadata":{"id":"QIYff7YyW-Bb","execution":{"iopub.status.busy":"2021-12-18T10:21:24.739363Z","iopub.execute_input":"2021-12-18T10:21:24.739856Z","iopub.status.idle":"2021-12-18T10:21:24.743704Z","shell.execute_reply.started":"2021-12-18T10:21:24.739810Z","shell.execute_reply":"2021-12-18T10:21:24.742914Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"x_transposed = x.transpose(1, 2)\nx_transposed.shape\n# перевели в (batch, input_size, seq_len)","metadata":{"id":"7tVn6YKLW-Bd","outputId":"6e66ab55-ce59-4501-eb11-2813020e73cc","execution":{"iopub.status.busy":"2021-12-18T10:21:24.745337Z","iopub.execute_input":"2021-12-18T10:21:24.745829Z","iopub.status.idle":"2021-12-18T10:21:24.759065Z","shell.execute_reply.started":"2021-12-18T10:21:24.745784Z","shell.execute_reply":"2021-12-18T10:21:24.757764Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"pred_transposed = cnn(x_transposed)\npred_transposed.shape\n# осталась разрмерность (batch, output_size, seq_len)","metadata":{"id":"2N4w6-iWW-Be","outputId":"e1b7864a-bb2f-4054-925c-bd69b4e53ee4","execution":{"iopub.status.busy":"2021-12-18T10:21:24.761265Z","iopub.execute_input":"2021-12-18T10:21:24.761965Z","iopub.status.idle":"2021-12-18T10:21:25.121336Z","shell.execute_reply.started":"2021-12-18T10:21:24.761912Z","shell.execute_reply":"2021-12-18T10:21:25.120327Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"# переведем обратно в (batch, seq_len, input_size)\npred = pred_transposed.transpose(1, 2)\npred.shape","metadata":{"id":"7-C3_phaW-Bf","outputId":"c070c882-0ae3-442d-ecd4-33de14e2cc74","execution":{"iopub.status.busy":"2021-12-18T10:21:25.123231Z","iopub.execute_input":"2021-12-18T10:21:25.123552Z","iopub.status.idle":"2021-12-18T10:21:25.132415Z","shell.execute_reply.started":"2021-12-18T10:21:25.123511Z","shell.execute_reply":"2021-12-18T10:21:25.131361Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"# Подготовим данные в DataLoader","metadata":{"id":"stBQ3yhqW-Bi"}},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader","metadata":{"id":"vPX_m5M4W-Bi","execution":{"iopub.status.busy":"2021-12-18T10:21:25.134416Z","iopub.execute_input":"2021-12-18T10:21:25.135023Z","iopub.status.idle":"2021-12-18T10:21:25.142688Z","shell.execute_reply.started":"2021-12-18T10:21:25.134955Z","shell.execute_reply":"2021-12-18T10:21:25.141720Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"'UNK' in word2index","metadata":{"id":"hV76BdN0W-Bj","outputId":"a603c39c-3d81-40f9-c615-9094ea15ed05","execution":{"iopub.status.busy":"2021-12-18T10:21:25.144405Z","iopub.execute_input":"2021-12-18T10:21:25.144901Z","iopub.status.idle":"2021-12-18T10:21:25.154768Z","shell.execute_reply.started":"2021-12-18T10:21:25.144854Z","shell.execute_reply":"2021-12-18T10:21:25.153716Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"id":"INB_dPAnW-Bk","outputId":"bc641e69-57c2-49a7-a32d-1dc3bc0b5bde","execution":{"iopub.status.busy":"2021-12-18T10:21:25.156520Z","iopub.execute_input":"2021-12-18T10:21:25.157773Z","iopub.status.idle":"2021-12-18T10:21:25.173103Z","shell.execute_reply.started":"2021-12-18T10:21:25.157719Z","shell.execute_reply":"2021-12-18T10:21:25.172123Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"markdown","source":"# Замапим категории в индексы","metadata":{"id":"1qv1mKAeW-Bl"}},{"cell_type":"code","source":"cat_mapper = {cat: n for n, cat in enumerate(data.category.unique())}","metadata":{"id":"iHeFzZe1W-Bl","execution":{"iopub.status.busy":"2021-12-18T10:21:25.175146Z","iopub.execute_input":"2021-12-18T10:21:25.176069Z","iopub.status.idle":"2021-12-18T10:21:25.206063Z","shell.execute_reply.started":"2021-12-18T10:21:25.175996Z","shell.execute_reply":"2021-12-18T10:21:25.204875Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"cat_mapper","metadata":{"id":"X3x9QhXYW-Bn","outputId":"e86721d0-4554-4c5a-961a-04331597acf9","execution":{"iopub.status.busy":"2021-12-18T10:21:25.207574Z","iopub.execute_input":"2021-12-18T10:21:25.208144Z","iopub.status.idle":"2021-12-18T10:21:25.215716Z","shell.execute_reply.started":"2021-12-18T10:21:25.208094Z","shell.execute_reply":"2021-12-18T10:21:25.214653Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"data.category = data.category.map(cat_mapper)","metadata":{"id":"ef--8SWbW-Bo","execution":{"iopub.status.busy":"2021-12-18T10:21:25.217850Z","iopub.execute_input":"2021-12-18T10:21:25.218495Z","iopub.status.idle":"2021-12-18T10:21:25.249698Z","shell.execute_reply.started":"2021-12-18T10:21:25.218412Z","shell.execute_reply":"2021-12-18T10:21:25.248754Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"markdown","source":"# Читалка данных","metadata":{"id":"vc48ALg_W-Bp"}},{"cell_type":"markdown","source":"## Что происходит ниже\n1. Мы задаем x_data, y_data (таргеты), word2index (маппер из слова в индекс слова), sequence_length (максимальная длина последовательности, если больше, ограничить ею), pad_token (токен паддинга и задаем его индекс pad_index).\n1. Загружаем данные:\n    1. Проходимся по датасету\n    1. Предобрабатываем каждый текст в датасете\n    1. Индексируем его\n    1. Паддим до нужной длины\n1. Когда нам нужно достать пример из датасета мы берем индексированный ```x``` и соответствующий этому индексу ```y```, наш ```x``` также паддим (или ограничиваем длину) и переводим в ```torch.Tensor(x).long()```. Для ```y``` этого делать не потребуется, в dataloader'е таргеты преобразуются в тензор сами.\n","metadata":{"id":"WFIQEv6nvE4c"}},{"cell_type":"code","source":"class WordData(Dataset):\n    \n    def __init__(self, x_data, y_data, word2index, sequence_length=32, pad_token='PAD', verbose=True):\n        \n        super().__init__()\n        \n        self.x_data = []\n        self.y_data = y_data\n        \n        self.word2index = word2index\n        self.sequence_length = sequence_length\n        \n        self.pad_token = pad_token\n        self.pad_index = self.word2index[self.pad_token]\n        \n        self.load(x_data, verbose=verbose)\n        \n    @staticmethod\n    def process_text(text):\n        \n        # Место для вашей предобработки\n        \n        words = wordpunct_tokenize(text.lower())\n        #words = re.findall('[a-яА-ЯеЁ]+', text.lower())\n        return words\n        \n    def load(self, data, verbose=True):\n        \n        data_iterator = tqdm(data, desc='Loading data', disable=not verbose)\n        \n        for text in data_iterator:\n            \n            words = self.process_text(text)\n            \n            indexed_words = self.indexing(words)\n            \n            self.x_data.append(indexed_words)\n    \n    def indexing(self, tokenized_text):\n\n        # здесь мы не используем токен UNK, потому что мы его специально не учили\n        # становится непонятно какой же эмбеддинг присвоить неизвестному слову,\n        # поэтому просто выбрасываем наши неизветсные слова\n        \n        return [self.word2index[word] for word in tokenized_text if word in self.word2index]\n    \n    def padding(self, sequence):\n        \n        # Ограничить длину self.sequence_length\n        # если длина меньше максимально - западить\n        if len(sequence)< self.sequence_length:\n            add_pad = self.sequence_length - len(sequence)\n            return sequence+[self.pad_index]*add_pad\n        else:\n            return sequence[:self.sequence_length]\n    \n    def __len__(self):\n        \n        return len(self.x_data)\n    \n    def __getitem__(self, idx):\n        \n        x = self.x_data[idx]\n        x = self.padding(x)\n        x = torch.Tensor(x).long()\n        \n        y = self.y_data[idx]\n        \n        return x, y","metadata":{"id":"ZkX8SC_sW-Bp","execution":{"iopub.status.busy":"2021-12-18T10:21:25.251629Z","iopub.execute_input":"2021-12-18T10:21:25.252250Z","iopub.status.idle":"2021-12-18T10:21:25.268210Z","shell.execute_reply.started":"2021-12-18T10:21:25.252197Z","shell.execute_reply":"2021-12-18T10:21:25.267070Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score","metadata":{"id":"R3WW8V9lyLm0","execution":{"iopub.status.busy":"2021-12-18T10:21:25.270417Z","iopub.execute_input":"2021-12-18T10:21:25.271030Z","iopub.status.idle":"2021-12-18T10:21:25.280912Z","shell.execute_reply.started":"2021-12-18T10:21:25.270959Z","shell.execute_reply":"2021-12-18T10:21:25.279863Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"x_train, x_validation, y_train, y_validation = train_test_split(data.text, data.category, test_size=0.1)\n\ntrain_dataset = WordData(list(x_train), list(y_train), word2index)\ntrain_loader = DataLoader(train_dataset, batch_size=64)\n\nvalidation_dataset = WordData(list(x_validation), list(y_validation), word2index)\nvalidation_loader = DataLoader(validation_dataset, batch_size=64)","metadata":{"id":"Lnc2nD8gW-Br","outputId":"970810ce-7898-4178-a10b-2418d7b00f5c","execution":{"iopub.status.busy":"2021-12-18T10:21:25.284639Z","iopub.execute_input":"2021-12-18T10:21:25.284944Z","iopub.status.idle":"2021-12-18T10:21:29.650695Z","shell.execute_reply.started":"2021-12-18T10:21:25.284902Z","shell.execute_reply":"2021-12-18T10:21:29.649674Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"for x, y in train_loader:\n    break","metadata":{"id":"dGeftxdgW-Br","execution":{"iopub.status.busy":"2021-12-18T10:21:29.652420Z","iopub.execute_input":"2021-12-18T10:21:29.652736Z","iopub.status.idle":"2021-12-18T10:21:29.665388Z","shell.execute_reply.started":"2021-12-18T10:21:29.652692Z","shell.execute_reply":"2021-12-18T10:21:29.664365Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"x","metadata":{"id":"nNkGQffBW-Bs","outputId":"479138d8-ee32-4b0f-e4b0-fde15eac5d2d","execution":{"iopub.status.busy":"2021-12-18T10:21:29.667973Z","iopub.execute_input":"2021-12-18T10:21:29.668741Z","iopub.status.idle":"2021-12-18T10:21:29.677636Z","shell.execute_reply.started":"2021-12-18T10:21:29.668693Z","shell.execute_reply":"2021-12-18T10:21:29.676663Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"y","metadata":{"id":"fxUk4nGcW-Bt","outputId":"b784e2a9-5558-45bc-f3c0-86a740817bb4","execution":{"iopub.status.busy":"2021-12-18T10:21:29.679542Z","iopub.execute_input":"2021-12-18T10:21:29.680277Z","iopub.status.idle":"2021-12-18T10:21:29.688769Z","shell.execute_reply.started":"2021-12-18T10:21:29.680214Z","shell.execute_reply":"2021-12-18T10:21:29.687651Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"markdown","source":"# Обучить нейронку","metadata":{"id":"Zy0dkkTIW-Bw"}},{"cell_type":"code","source":"from torch import nn, optim","metadata":{"id":"GDxW55CXcgCL","execution":{"iopub.status.busy":"2021-12-18T10:21:29.691113Z","iopub.execute_input":"2021-12-18T10:21:29.691739Z","iopub.status.idle":"2021-12-18T10:21:29.696389Z","shell.execute_reply.started":"2021-12-18T10:21:29.691693Z","shell.execute_reply":"2021-12-18T10:21:29.695343Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"from math import sqrt\n\nclass model_with_att(torch.nn.Module):\n    def __init__(self, matrix_w, n, hidden_size=256, conv_out=128, lin_out=256): #n - количество категорий\n        super().__init__()\n        self.n = n\n        self.embedding_dim = matrix_w.shape[1]\n\n        self.hidden_size = hidden_size\n        self.conv_out = conv_out\n        self.lin_out = lin_out\n\n        self.emb_layer = torch.nn.Embedding.from_pretrained(torch.Tensor(matrix_w))\n\n        # задайте лстм, можно 2 уровня, лучше бидирекциональный, в доке торча есть инофрмация как это сделать в одну строчку\n        self.LSTM = nn.LSTM(input_size=self.embedding_dim, hidden_size=self.hidden_size,\n                            num_layers=2, batch_first=True, bidirectional=True, dropout=0.1)\n\n        # три линейных преобразования, размерность совпадает с выходом из лстм (если БИлстм то надо умножить ее на 2)\n        self.q_proj = nn.Linear(in_features=self.hidden_size*2, out_features=self.hidden_size)\n        self.k_proj = nn.Linear(in_features=self.hidden_size*2, out_features=self.hidden_size)\n        self.v_proj = nn.Linear(in_features=self.hidden_size*2, out_features=self.hidden_size)\n\n        self.att_soft = torch.nn.Softmax(dim = 2)\n        \n        # три конволюционных фильтра с разными ядрами (3,4,5) чтобы были всякие нграммы ловить\n        self.cnn_3gr = nn.Conv1d(in_channels=self.hidden_size, out_channels=self.conv_out,\n                                 kernel_size=3, padding='same')\n        self.cnn_4gr = nn.Conv1d(in_channels=self.hidden_size, out_channels=self.conv_out,\n                                 kernel_size=4, padding='same')\n        self.cnn_5gr = nn.Conv1d(in_channels=self.hidden_size, out_channels=self.conv_out,\n                                 kernel_size=5, padding='same')\n\n        # сверху накидываем два полносвязных слоя для классификации\n        self.linear_1 = nn.Linear(in_features=self.conv_out*3, out_features=self.lin_out)\n        self.relu = torch.nn.ReLU()\n        self.linear_2 = torch.nn.Linear(in_features=lin_out, out_features=n) \n\n        \n    def forward(self, x):\n        #примените эмбеддинги\n        x_emb = self.emb_layer(x)\n        # транспонируйте тензор для лстм как было описано выше\n        # нет нужды, т.к. batch_first=True\n        # применим лстм, не забываем что на выходе у него много всяких последовательностей, нам нужна только эта\n        x, _ = self.LSTM(x_emb)\n        # транспонируйте обратно\n\n        x_q = self.q_proj(x) #применим линейные преобразования для селф-эттеншена\n        x_k = self.k_proj(x)\n        x_v = self.v_proj(x)\n        x_k_t = x_k.transpose(2,1)\n        # посмотрите в презентацию и перемножьте нужные тензора изспольуя функцию bmm из торча, перед этим одну из матриц обзательно транспонируйте\n        # результат обязательно поделите на корень из последней размерности (то есть на размер эмбеддинга из предыдущего слоя)\n        att_scores = torch.bmm(x_q, x_k_t) / sqrt(self.embedding_dim)\n\n        att_dist = self.att_soft(att_scores) # накидываем софтмакс\n        # тут тоже что то с чем то нужно перемножить :)\n        attention_vectors = torch.bmm(att_dist, x_v)\n\n        x_att = attention_vectors.transpose(2,1) #транспонируем для конволюционных фильтров\n\n        x_cnn3 = self.cnn_3gr(x_att)\n        x_cnn4 = self.cnn_4gr(x_att)\n        x_cnn5 = self.cnn_5gr(x_att)\n\n        frst, _ =  x_cnn3.max(dim= -1,) # cделаем макс пуллинг\n        sc, _ = x_cnn4.max(dim= -1,)\n        thr, _ = x_cnn5.max(dim= -1,)\n      \n        x_cat = torch.cat((frst, sc, thr), dim=-1) # а теперь объединим результаты\n      \n        # пару полносвязных слоев с релу для классификации\n        x = self.linear_1(x_cat)\n        x = self.relu(x)    \n        x = self.linear_2(x)\n    \n        return x","metadata":{"id":"3wwkxZm1vE43","execution":{"iopub.status.busy":"2021-12-18T10:22:25.035365Z","iopub.execute_input":"2021-12-18T10:22:25.035712Z","iopub.status.idle":"2021-12-18T10:22:25.059117Z","shell.execute_reply.started":"2021-12-18T10:22:25.035678Z","shell.execute_reply":"2021-12-18T10:22:25.057415Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"n_classes = data.category.unique().shape[0]","metadata":{"id":"jFbyUXLE0WPv","execution":{"iopub.status.busy":"2021-12-18T10:22:35.236249Z","iopub.execute_input":"2021-12-18T10:22:35.236826Z","iopub.status.idle":"2021-12-18T10:22:35.245397Z","shell.execute_reply.started":"2021-12-18T10:22:35.236773Z","shell.execute_reply":"2021-12-18T10:22:35.244491Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"model = model_with_att(vectors, n_classes)","metadata":{"id":"OZgh4ONx0HvT","execution":{"iopub.status.busy":"2021-12-18T10:22:36.758043Z","iopub.execute_input":"2021-12-18T10:22:36.758764Z","iopub.status.idle":"2021-12-18T10:22:36.938441Z","shell.execute_reply.started":"2021-12-18T10:22:36.758694Z","shell.execute_reply":"2021-12-18T10:22:36.937413Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"model #если сделать batch_first=True, то можно не транспонировать батчи","metadata":{"id":"CNO6VSbJgQ36","outputId":"2cdbc5af-2132-4102-bdd6-c1c63ddd1d03","execution":{"iopub.status.busy":"2021-12-18T10:22:44.858365Z","iopub.execute_input":"2021-12-18T10:22:44.859130Z","iopub.status.idle":"2021-12-18T10:22:44.865771Z","shell.execute_reply.started":"2021-12-18T10:22:44.859078Z","shell.execute_reply":"2021-12-18T10:22:44.864981Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')","metadata":{"id":"bL6zIZSt0h9W","execution":{"iopub.status.busy":"2021-12-18T10:22:45.707290Z","iopub.execute_input":"2021-12-18T10:22:45.707898Z","iopub.status.idle":"2021-12-18T10:22:45.712840Z","shell.execute_reply.started":"2021-12-18T10:22:45.707854Z","shell.execute_reply":"2021-12-18T10:22:45.712047Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"criterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(params=model.parameters())\n\nmodel = model.to(device)\ncriterion = criterion.to(device)","metadata":{"id":"Vsxw4M2m0m2B","execution":{"iopub.status.busy":"2021-12-18T10:22:49.439842Z","iopub.execute_input":"2021-12-18T10:22:49.440510Z","iopub.status.idle":"2021-12-18T10:22:49.495346Z","shell.execute_reply.started":"2021-12-18T10:22:49.440469Z","shell.execute_reply":"2021-12-18T10:22:49.494493Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"epochs = 10\nlosses = []\nbest_test_loss = 10.\n\ntest_f1 = []\n\nfor n_epoch in range(epochs):\n    \n    train_losses = []\n    test_losses = []\n    test_targets = []\n    test_pred_class = []\n    \n    progress_bar = tqdm(total=len(train_loader.dataset), position=0, leave=True,\n                        desc='Epoch {}'.format(n_epoch + 1))\n    \n    model.train()\n    \n    for x, y in train_loader:\n\n        x = x.to(device)\n        y = y.to(device)\n        \n        optimizer.zero_grad()\n        \n        pred = model(x)\n        loss = criterion(pred, y)\n        \n        loss.backward()\n        \n        optimizer.step()\n        \n        train_losses.append(loss.item())\n        losses.append(loss.item())\n        \n        progress_bar.set_postfix(train_loss = np.mean(losses[-500:]))\n\n        progress_bar.update(x.shape[0])\n        \n    progress_bar.close()\n    \n    model.eval()\n    \n    for x, y in validation_loader:\n        \n        x = x.to(device)\n\n        with torch.no_grad():\n\n            pred = model(x)\n\n            pred = pred.cpu()\n\n            test_targets.append(y.numpy())\n            test_pred_class.append(np.argmax(pred, axis=1))\n\n            loss = criterion(pred, y)\n\n            test_losses.append(loss.item())\n        \n    mean_test_loss = np.mean(test_losses)\n\n    test_targets = np.concatenate(test_targets).squeeze()\n    test_pred_class = np.concatenate(test_pred_class).squeeze()\n\n    f1 = f1_score(test_targets, test_pred_class, average='micro')\n\n    test_f1.append(f1)\n    \n    print('Losses: train - {:.3f}, test - {:.3f}'.format(np.mean(train_losses), mean_test_loss))\n\n    print('F1 test - {:.3f}'.format(f1))\n        \n    # Early stopping:\n    if mean_test_loss < best_test_loss:\n        best_test_loss = mean_test_loss\n    else:\n        print('Early stopping')\n        break","metadata":{"id":"7rUTc0l60pV9","outputId":"be0666d6-027a-4dfe-9ff9-b51244007a91","execution":{"iopub.status.busy":"2021-12-18T10:22:56.450642Z","iopub.execute_input":"2021-12-18T10:22:56.451714Z","iopub.status.idle":"2021-12-18T10:30:22.005920Z","shell.execute_reply.started":"2021-12-18T10:22:56.451663Z","shell.execute_reply":"2021-12-18T10:30:22.005064Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"markdown","source":"Если вы запускаете много раз колаб окна и ткдм начинает беситься, можно запустить окно ниже, ткдм обновится и все снова станет хорошо","metadata":{"id":"1TMaPbh3oWwc"}},{"cell_type":"code","source":"for instance in list(tqdm._instances): \n    tqdm._decr_instances(instance)","metadata":{"id":"_aPjTQcR0vm2","execution":{"iopub.status.busy":"2021-12-18T12:13:33.703677Z","iopub.execute_input":"2021-12-18T12:13:33.703934Z","iopub.status.idle":"2021-12-18T12:13:33.707819Z","shell.execute_reply.started":"2021-12-18T12:13:33.703906Z","shell.execute_reply":"2021-12-18T12:13:33.706884Z"},"trusted":true},"execution_count":113,"outputs":[]},{"cell_type":"markdown","source":"# Оценка\n1. Добрались сюда - очень хорошо - получилась такая же точность или около того - 7 баллов.\n2. Поставили эксперименты и повысили точность относительно своей и не ниже F1 test - 0.841 - 8 баллов.\n3. Запустили бертовую тетрадку и разобрались. Получился сравнимый результат - 10 баллов ","metadata":{"id":"wFc6DUF9VhR4"}},{"cell_type":"markdown","source":"# Улучшение\nХочу попробовать добавить больше параметров и слоёв!","metadata":{"id":"0auggr7UbCxk"}},{"cell_type":"code","source":"from IPython import display\ndisplay.Image('https://habrastorage.org/files/040/6ca/59e/0406ca59e7c243e1bffae413d1d40947.png',\n              width = 400)","metadata":{"id":"KFITrSjEbXaS","outputId":"d9676be0-8877-4de1-f8f2-88e0565865ae","execution":{"iopub.status.busy":"2021-12-18T10:35:56.621321Z","iopub.execute_input":"2021-12-18T10:35:56.621630Z","iopub.status.idle":"2021-12-18T10:35:58.419109Z","shell.execute_reply.started":"2021-12-18T10:35:56.621594Z","shell.execute_reply":"2021-12-18T10:35:58.418302Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"class ImprovedModel(torch.nn.Module):\n    def __init__(self, matrix_w, n, hidden_size=300, conv_out=200, lin_out=300): #n - количество категорий\n        super().__init__()\n        self.n = n\n        self.embedding_dim = matrix_w.shape[1]\n\n        self.hidden_size = hidden_size\n        self.conv_out = conv_out\n        self.lin_out = lin_out\n\n        self.emb_layer = torch.nn.Embedding.from_pretrained(torch.Tensor(matrix_w), freeze=True)\n\n        # задайте лстм, можно 2 уровня, лучше бидирекциональный, в доке торча есть информация как это сделать в одну строчку\n        self.biLSTM = nn.LSTM(input_size=self.embedding_dim, hidden_size=int(self.hidden_size*1.25),\n                            num_layers=2, batch_first=True, bidirectional=True, dropout=0.4)\n        # поверх би- хочу обычную\n        self.LSTM = nn.LSTM(input_size=int(self.hidden_size*1.25), hidden_size=self.hidden_size,\n                            num_layers=1, batch_first=True)\n\n        # три линейных преобразования, размерность совпадает с выходом из лстм (если БИлстм то надо умножить ее на 2)\n        self.q_proj = nn.Linear(in_features=self.hidden_size, out_features=self.hidden_size)\n        self.k_proj = nn.Linear(in_features=self.hidden_size, out_features=self.hidden_size)\n        self.v_proj = nn.Linear(in_features=self.hidden_size, out_features=self.hidden_size)\n\n        self.att_soft = torch.nn.Softmax(dim = 2)\n        \n        # три конволюционных фильтра с разными ядрами (3,4,5) чтобы были всякие нграммы ловить\n        # а потом ещё триграммы по сумме 3,4,5\n        self.cnn_3gr = nn.Conv1d(in_channels=self.hidden_size, out_channels=self.conv_out,\n                                 kernel_size=3, padding='same')\n        self.cnn_4gr = nn.Conv1d(in_channels=self.hidden_size, out_channels=self.conv_out,\n                                 kernel_size=4, padding='same')\n        self.cnn_5gr = nn.Conv1d(in_channels=self.hidden_size, out_channels=self.conv_out,\n                                 kernel_size=5, padding='same')\n        self.cnn_cat = nn.Conv1d(in_channels=self.conv_out*3, out_channels=self.conv_out,\n                                 kernel_size=3, padding='same')\n\n        # сверху накидываем два полносвязных слоя для классификации\n        self.linear_1 = nn.Linear(in_features=self.conv_out, out_features=self.lin_out)\n        self.relu = torch.nn.PReLU()\n        self.linear_2 = torch.nn.Linear(in_features=lin_out, out_features=n) \n\n        \n    def forward(self, x):\n        #примените эмбеддинги\n        x_emb = self.emb_layer(x)\n        # транспонируйте тензор для лстм как было описано выше\n        # нет нужды, т.к. batch_first=True\n        # хочу два слоя biLSTM, а потом ещё два обычной\n        _, (h, _) = self.biLSTM(x_emb)\n        h = h.transpose(0,1)\n        x, _ = self.LSTM(h)\n        # транспонируйте обратно\n\n        x_q = self.q_proj(x) #применим линейные преобразования для селф-эттеншена\n        x_k = self.k_proj(x)\n        x_v = self.v_proj(x)\n        x_k_t = x_k.transpose(2,1)\n        # посмотрите в презентацию и перемножьте нужные тензора изспольуя функцию bmm из торча, перед этим одну из матриц обзательно транспонируйте\n        # результат обязательно поделите на корень из последней размерности (то есть на размер эмбеддинга из предыдущего слоя)\n        att_scores = torch.bmm(x_q, x_k_t) / sqrt(self.embedding_dim)\n\n        att_dist = self.att_soft(att_scores) # накидываем софтмакс\n        # тут тоже что то с чем то нужно перемножить :)\n        attention_vectors = torch.bmm(att_dist, x_v)\n\n        x_att = attention_vectors.transpose(2,1) #транспонируем для конволюционных фильтров\n\n        x_cnn3 = self.cnn_3gr(x_att)\n        x_cnn4 = self.cnn_4gr(x_att)\n        x_cnn5 = self.cnn_5gr(x_att)\n        x_cat = torch.cat((x_cnn3, x_cnn4, x_cnn5), dim=1) # а теперь объединим результаты\n        conv_cat = self.cnn_cat(x_cat)\n        \n        pooled, _ =  conv_cat.max(dim= -1,) # cделаем макс пуллинг\n      \n        # пару полносвязных слоев с релу для классификации\n        x = self.linear_1(pooled)\n        x = self.relu(x)    \n        x = self.linear_2(x)\n    \n        return x","metadata":{"id":"e5BgHdtW2sO3","execution":{"iopub.status.busy":"2021-12-18T12:43:27.024783Z","iopub.execute_input":"2021-12-18T12:43:27.025070Z","iopub.status.idle":"2021-12-18T12:43:27.046144Z","shell.execute_reply.started":"2021-12-18T12:43:27.025038Z","shell.execute_reply":"2021-12-18T12:43:27.045198Z"},"trusted":true},"execution_count":123,"outputs":[]},{"cell_type":"code","source":"improved_model = ImprovedModel(vectors, n_classes)\n\ncriterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(params=improved_model.parameters())\n\nimproved_model = improved_model.to(device)\ncriterion = criterion.to(device)","metadata":{"id":"IlIu6BIllbq5","execution":{"iopub.status.busy":"2021-12-18T12:43:27.558459Z","iopub.execute_input":"2021-12-18T12:43:27.561278Z","iopub.status.idle":"2021-12-18T12:43:27.888730Z","shell.execute_reply.started":"2021-12-18T12:43:27.561227Z","shell.execute_reply":"2021-12-18T12:43:27.887671Z"},"trusted":true},"execution_count":124,"outputs":[]},{"cell_type":"code","source":"improved_model","metadata":{"execution":{"iopub.status.busy":"2021-12-18T13:03:17.276432Z","iopub.execute_input":"2021-12-18T13:03:17.276693Z","iopub.status.idle":"2021-12-18T13:03:17.282603Z","shell.execute_reply.started":"2021-12-18T13:03:17.276664Z","shell.execute_reply":"2021-12-18T13:03:17.281904Z"},"trusted":true},"execution_count":128,"outputs":[]},{"cell_type":"code","source":"epochs = 10\nlosses = []\nbest_test_loss = 10.\n\ntest_f1 = []\n\nfor n_epoch in range(epochs):\n    \n    train_losses = []\n    test_losses = []\n    test_targets = []\n    test_pred_class = []\n    \n    progress_bar = tqdm(total=len(train_loader.dataset), position=0, leave=True,\n                        desc='Epoch {}'.format(n_epoch + 1))\n    \n    improved_model.train()\n    \n    for x, y in train_loader:\n\n        x = x.to(device)\n        y = y.to(device)\n        \n        optimizer.zero_grad()\n        \n        pred = improved_model(x)\n        \n        loss = criterion(pred, y)\n        \n        loss.backward()\n        \n        optimizer.step()\n        \n        train_losses.append(loss.item())\n        losses.append(loss.item())\n        \n        progress_bar.set_postfix(train_loss = np.mean(losses[-500:]))\n\n        progress_bar.update(x.shape[0])\n        \n    progress_bar.close()\n    \n    improved_model.eval()\n    \n    for x, y in validation_loader:\n        \n        x = x.to(device)\n\n        with torch.no_grad():\n\n            pred = improved_model(x)\n\n            pred = pred.cpu()\n\n            test_targets.append(y.numpy())\n            test_pred_class.append(np.argmax(pred, axis=1))\n\n            loss = criterion(pred, y)\n\n            test_losses.append(loss.item())\n        \n    mean_test_loss = np.mean(test_losses)\n\n    test_targets = np.concatenate(test_targets).squeeze()\n    test_pred_class = np.concatenate(test_pred_class).squeeze()\n\n    f1 = f1_score(test_targets, test_pred_class, average='micro')\n\n    test_f1.append(f1)\n    \n    print('Losses: train - {:.3f}, test - {:.3f}'.format(np.mean(train_losses), mean_test_loss))\n\n    print('F1 test - {:.3f}'.format(f1))\n        \n    # Early stopping:\n    if mean_test_loss < best_test_loss:\n        best_test_loss = mean_test_loss\n    else:\n        print('Early stopping')\n        break","metadata":{"id":"xpfw_0oDlNK8","outputId":"ff0bed9c-4359-423f-929b-0a0dddcf7ca9","execution":{"iopub.status.busy":"2021-12-18T12:43:28.115260Z","iopub.execute_input":"2021-12-18T12:43:28.117616Z","iopub.status.idle":"2021-12-18T12:53:29.034580Z","shell.execute_reply.started":"2021-12-18T12:43:28.117535Z","shell.execute_reply":"2021-12-18T12:53:29.033714Z"},"trusted":true},"execution_count":125,"outputs":[]},{"cell_type":"markdown","source":"Успех! На базовой модели в последних двух эпохах f1 был 0.844, на этой модели также на последних двух 0.846. Что поменялось:\n* поверх двух слоёв biLSTM добавила один слой обычной LSTM\n* у biLSTM увеличила дропаут с 0.1 до 0.4\n* сложила свёртки 3-, 4- и 5-тиграмм и поверх этого сделала ещё один свёрточный слой с окном 3, только затем пулинг\n* увеличила количество параметров: hidden size и lin out с 256 до 300, conv_out с 128 до 200\n* заменила ReLU на PReLU","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}